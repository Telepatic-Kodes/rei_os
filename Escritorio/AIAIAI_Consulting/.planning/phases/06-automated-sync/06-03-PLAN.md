---
phase: 06-automated-sync
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - app/src/lib/analytics.ts
  - app/src/lib/sync-manager.ts
  - app/src/lib/schemas.ts
  - data/analytics.json
autonomous: true

must_haves:
  truths:
    - "Each sync run generates pre-computed analytics in data/analytics.json"
    - "Analytics include 7-day, 30-day, and 90-day time windows"
    - "Each window contains totalCost, tokensIn, tokensOut, byModel breakdown, and burnRate"
    - "Each sync run appends a daily snapshot to JSONL history files"
    - "analytics.json is readable by server components for Phase 7 charts"
  artifacts:
    - path: "app/src/lib/analytics.ts"
      provides: "generateAnalytics() function computing metrics from token data and JSONL history"
      exports: ["generateAnalytics"]
    - path: "data/analytics.json"
      provides: "Pre-computed analytics with nested time windows"
      contains: "windows"
  key_links:
    - from: "app/src/lib/sync-manager.ts"
      to: "app/src/lib/analytics.ts"
      via: "import generateAnalytics, called after sync scripts"
      pattern: "generateAnalytics"
    - from: "app/src/lib/analytics.ts"
      to: "data/tokens.json"
      via: "readFileSync + TokenDataSchema.parse"
      pattern: "TokenDataSchema"
---

<objective>
Add JSONL history snapshot recording and pre-computed analytics generation to the sync pipeline.

Purpose: History enables trend analysis; pre-computed analytics means Phase 7 charts just render static data with zero client-side calculation.
Output: analytics.ts generator, updated sync-manager.ts calling it, analytics.json output, Zod schema for analytics.
</objective>

<execution_context>
@/home/tomas/.claude/get-shit-done/workflows/execute-plan.md
@/home/tomas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-automated-sync/06-RESEARCH.md
@.planning/phases/06-automated-sync/06-01-SUMMARY.md

@app/src/lib/sync-manager.ts
@app/src/lib/schemas.ts
@app/src/lib/atomic-write.ts
@app/src/lib/jsonl.ts
@app/src/lib/data.ts
@data/tokens.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analytics generator</name>
  <files>app/src/lib/analytics.ts, app/src/lib/schemas.ts</files>
  <action>
    Add AnalyticsSchema to `app/src/lib/schemas.ts`:
    ```
    AnalyticsWindowSchema: {
      totalCost: z.number(),
      tokensIn: z.number(),
      tokensOut: z.number(),
      byModel: z.record(z.string(), z.object({
        cost: z.number(),
        tokensIn: z.number(),
        tokensOut: z.number()
      })),
      burnRate: z.number()  // daily average cost
    }
    AnalyticsSchema: {
      generatedAt: z.string(),
      windows: z.object({
        "7d": AnalyticsWindowSchema,
        "30d": AnalyticsWindowSchema,
        "90d": AnalyticsWindowSchema
      })
    }
    ```
    Export the types.

    Create `app/src/lib/analytics.ts`:
    - Export `async function generateAnalytics(): Promise<void>`
    - Read `data/tokens.json` using readFileSync, parse with TokenDataSchema
    - For each window (7, 30, 90 days):
      - Calculate cutoff date (today minus N days, as YYYY-MM-DD string)
      - Filter token entries where entry.date >= cutoff
      - Sum totalCost, tokensIn, tokensOut
      - Group by model for byModel breakdown
      - Calculate burnRate = totalCost / days
    - Write result to `data/analytics.json` using atomicWriteJson
    - Log "Analytics pre-computed for 7d, 30d, 90d windows"
    - Add `data/analytics.json` to .gitignore (auto-generated file)

    Handle edge case: if tokens.json has no entries or doesn't exist, write analytics with all zeros.
  </action>
  <verify>
    Run `cd app && npx tsx -e "import {generateAnalytics} from './src/lib/analytics'; generateAnalytics().then(() => console.log('done'))"` and check that `data/analytics.json` is created with valid structure.
  </verify>
  <done>generateAnalytics() reads token data, computes 7d/30d/90d metrics, and writes analytics.json with totals, per-model breakdown, and burn rate.</done>
</task>

<task type="auto">
  <name>Task 2: Integrate analytics into sync pipeline and ensure history snapshots</name>
  <files>app/src/lib/sync-manager.ts</files>
  <action>
    Update `app/src/lib/sync-manager.ts` to call generateAnalytics() after all three sync scripts complete but before writing success status.

    The flow should be:
    1. Acquire lock
    2. Run sync-tokens (which already appends to JSONL history via appendJsonl from Phase 5)
    3. Run sync-quality (same -- already writes JSONL history)
    4. Run sync-projects (same)
    5. Call generateAnalytics() -- NEW
    6. Write sync-status.json with success
    7. Release lock

    Import generateAnalytics from "./analytics".

    Verify that existing sync scripts (sync-tokens.ts, sync-quality.ts, sync-projects.ts) already call appendJsonl for history recording (they should from Phase 5). If any script does NOT append to JSONL history, add the call. Check each script file to confirm.

    The history JSONL files should be at:
    - data/history/tokens-YYYY-MM.jsonl
    - data/history/quality-YYYY-MM.jsonl

    If sync-projects doesn't write history (projects change rarely), that's fine -- no history needed for projects.
  </action>
  <verify>
    Run the full sync (via `npm run cron` and wait for a tick, or call runAllSyncs directly).
    Verify: `data/analytics.json` exists with generatedAt timestamp.
    Verify: `data/history/tokens-*.jsonl` has entries.
    Verify: `data/sync-status.json` shows success.
  </verify>
  <done>
    Every sync run (automatic or manual) generates fresh analytics.json and appends daily snapshots to JSONL history.
    Analytics are ready for Phase 7 charts to consume as static JSON.
  </done>
</task>

</tasks>

<verification>
1. `data/analytics.json` exists after sync with valid structure (generatedAt + 3 windows)
2. Each window has totalCost, tokensIn, tokensOut, byModel, burnRate
3. `data/history/tokens-YYYY-MM.jsonl` grows with each sync run
4. Analytics values match manual calculation from tokens.json
5. Schema validates: parse analytics.json with AnalyticsSchema without errors
</verification>

<success_criteria>
- Pre-computed analytics generated on every sync with 7d, 30d, 90d windows
- JSONL history files appended to on each sync (daily snapshots)
- analytics.json serves as the single data source for Phase 7 charts
- Zero client-side analytics calculation required
</success_criteria>

<output>
After completion, create `.planning/phases/06-automated-sync/06-03-SUMMARY.md`
</output>
